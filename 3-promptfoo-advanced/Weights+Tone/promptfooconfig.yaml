# 4) French greeting: correctness + tone + (cheap OR fast)
description: "Require a friendly French greeting that includes 'Bonjour' and stays within budget (either cheap or fast)."
providers:
  - openai:gpt-4o-mini

prompts:
  - "Greet the user in French."

tests:
  - threshold: 0.8
    assert:
      - type: contains 
        value: "Bonjour"
        weight: 2
        metric: Correctness

      - type: llm-rubric 
        value: "Tone is friendly and the text is in French."
        weight: 1
        metric: Tone

      - type: answer-relevance #this assertion type uses LLLM to judge if the answer is on-topic, so the score here can be between 0 and 1! 
        threshold: 0.8
        weight: 1
        metric: Topicality

      - type: assert-set # group related assertions under a single metric.
        threshold: 0.5
        metric: Performance
        assert:
          - type: cost
            threshold: 0.0008
          - type: latency
            threshold: 500

#.       ASSIGNED SCORE IS ALWAYS IN COMBO WITH PROMPTFOO GRADED SCORE

        # here is how the final score is calculated: “This is a simplified illustration. In reality, LLM-graded assertions return fractional scores between 0 and 1.”

        # Metric     | Score | Weight | Weighted Score ( = Weight x Score)
        # factuality | 1     | 3      | 3
        # icontains  | 1     | 1      | 1
        # conciseness| 0     | 1      | 0

        # TOTAL      | 2.    | 5      | 4
        # Final Score = 4 / 5 = 0.8


#        # scores can be gradual depending on the metric: 
        # Examples:
        # - llm-rubric              # 0.0 to 1.0 (e.g., 0.85)
        # - similarity              # 0.0 to 1.0 (cosine similarity)
        # - factuality              # 0.0 to 1.0 (LLM-judged)
        # - answer-relevance        # 0.0 to 1.0
        # - context-relevance       # 0.0 to 1.0
        # - perplexity              # Normalized to 0.0 to 1.0. 